{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "q3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSTM2HUJwQ1O"
      },
      "source": [
        "!cp drive/My\\ Drive/natural-language-processing/q3_train.zip ."
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atxLTI4Ltohz",
        "outputId": "4980b5ea-8153-4e21-cc62-267217c59a57"
      },
      "source": [
        "!unzip q3_train.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  q3_train.zip\n",
            "   creating: train/\n",
            "  inflating: train/test.csv          \n",
            "  inflating: train/train.csv         \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfT2GSuGLUyK"
      },
      "source": [
        "#### Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2Q2z0MbwmU8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d7adcdc-c736-4c52-d136-430b41b9d9a2"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "from keras.utils import to_categorical\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.corpus import stopwords\n",
        "tqdm.pandas()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4LvpfX5LY8Z"
      },
      "source": [
        "#### Loading dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYn-SLmexYNs"
      },
      "source": [
        "df = pd.read_csv('train/train.csv')\n",
        "df_test = pd.read_csv('train/test.csv')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "9-0dJnTNxHQI",
        "outputId": "c61f8b3f-3c3c-45b1-c70b-56c10477516f"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I do.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What if anything was decided about whether I s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>H: If Roubini is right and he's been mostly ri...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HRC: Below is an oped on the National Security...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>DQoNCg0KDQoNCg0KDQpHb29kIERheSwNCk1heSBpdCBub3...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  Class\n",
              "0                                              I do.      0\n",
              "1  What if anything was decided about whether I s...      0\n",
              "2  H: If Roubini is right and he's been mostly ri...      0\n",
              "3  HRC: Below is an oped on the National Security...      0\n",
              "4  DQoNCg0KDQoNCg0KDQpHb29kIERheSwNCk1heSBpdCBub3...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8LOMkcF0k0K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "98ec75b9-0724-4640-8385-b084ff6b459b"
      },
      "source": [
        "df_test.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>FROM BONGO WALEJOHANNESBURG,SOUTH AFRICA.TELL:...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MR=2E DONALD COLLINSCREDIT MUTUEL DU SENEGAL B...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Meant to write that Solomon is a tough critic.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Well well</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>#226=2C TAYO RIMI=2CMEDINA=2CDAKAR=2C SENEGAL=...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text\n",
              "0  FROM BONGO WALEJOHANNESBURG,SOUTH AFRICA.TELL:...\n",
              "1  MR=2E DONALD COLLINSCREDIT MUTUEL DU SENEGAL B...\n",
              "2     Meant to write that Solomon is a tough critic.\n",
              "3                                          Well well\n",
              "4  #226=2C TAYO RIMI=2CMEDINA=2CDAKAR=2C SENEGAL=..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpXETN8uL1bK"
      },
      "source": [
        "#### Checking Nan values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9Evcls03m2C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afa461d1-71be-4dd2-e4e6-e283a627269a"
      },
      "source": [
        "df.isna().sum()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text     1\n",
              "Class    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_ZewItrL6nw"
      },
      "source": [
        "#### Data Pre-processing\r\n",
        "- Nan values removal\r\n",
        "- Normalization\r\n",
        "- Punctuation removal\r\n",
        "- Stop words removal\r\n",
        "- Lemmatization\r\n",
        "- Removing words having length of less than two\r\n",
        "- Tokenization\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cGsXofgt9YN"
      },
      "source": [
        "df.dropna(inplace=True)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AAuiQhuCueI"
      },
      "source": [
        "df['Class'] = df['Class'].astype(int)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgBe5Frn3oxq"
      },
      "source": [
        "def clean_data(text):\n",
        "   lower = text.lower()\n",
        "   splitted = lower.split()\n",
        "   re_punc = re.compile('[%s]' % re.escape(string.punctuation))\n",
        "   tokens = [re_punc.sub('',w) for w in splitted]\n",
        "   tokens = [word for word in tokens if word.isalpha()]\n",
        "   stop_words = set(stopwords.words('english'))\n",
        "   tokens = [w for w in tokens if not w in stop_words]\n",
        "   lemmeted = [WordNetLemmatizer().lemmatize(w) for w in tokens]\n",
        "   tokens = [word for word in lemmeted if len(word) > 2]\n",
        "   return tokens"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yu3r2GCBMWWn"
      },
      "source": [
        "#### Train/Test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbjNB7Ve4JF5"
      },
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(df['Text'], df['Class'])\n",
        "vocab = Counter()\n",
        "for index, row in x_train.iteritems():\n",
        "  vocab.update(clean_data(row))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rh680jjMMakY"
      },
      "source": [
        "#### Most common words in the vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3uuC1bD8kc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70b9ad72-ed12-466d-97ac-2346265ed485"
      },
      "source": [
        "vocab.most_common(10)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('money', 6747),\n",
              " ('account', 5421),\n",
              " ('bank', 5282),\n",
              " ('fund', 4782),\n",
              " ('business', 3069),\n",
              " ('country', 2993),\n",
              " ('next', 2730),\n",
              " ('transaction', 2635),\n",
              " ('transfer', 2496),\n",
              " ('want', 2494)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmuR-CqO8zVX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e432279-ac53-4378-9f2f-486cfc2a8295"
      },
      "source": [
        "vocab_size = len(vocab)\n",
        "print(\"Vocabulary Size is: \", vocab_size)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary Size is:  67860\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwR9LeKbMjFv"
      },
      "source": [
        "#### Feature extraction \r\n",
        "- TF-IDF Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CVzAa5C86tn"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "v = TfidfVectorizer(vocabulary=vocab.keys())\n",
        "x_train = v.fit_transform(x_train)\n",
        "x_val = v.fit_transform(x_val)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nevyMvHyMoa3"
      },
      "source": [
        "#### Model preparation\r\n",
        "- SVM with Linear kernel\r\n",
        "- Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2JTZpBn_etf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cc9888b-f4a8-4aee-d658-d4a6ce0b7d71"
      },
      "source": [
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# probability=True -> predict_proba\n",
        "model = SVC(kernel='linear', probability=True)\n",
        "model.fit(x_train, y_train)\n",
        "pred = model.predict(x_val)\n",
        "print(classification_report(y_val, pred))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.99      1378\n",
            "           1       1.00      0.96      0.98      1008\n",
            "\n",
            "    accuracy                           0.98      2386\n",
            "   macro avg       0.99      0.98      0.98      2386\n",
            "weighted avg       0.98      0.98      0.98      2386\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-K7NDgNUM0WJ"
      },
      "source": [
        "#### Evaluation & Prediction\r\n",
        "- Transforming test set for feature extraction\r\n",
        "- Submiting to a CSV file\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JWdwcF_vKpx"
      },
      "source": [
        "x_test = v.transform(df_test['Text'].values)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INjcRvzEvPJh"
      },
      "source": [
        "y_pred_prob = model.predict_proba(x_test)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6v_rqIkvTgi"
      },
      "source": [
        "d = pd.DataFrame(y_pred_prob.argmax(axis=1), columns=['Class'])\r\n",
        "d.to_csv('submit.csv', index=False)"
      ],
      "execution_count": 21,
      "outputs": []
    }
  ]
}